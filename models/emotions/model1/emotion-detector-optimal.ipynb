{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\davia\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","    #for filename in filenames:\n","        #print(os.path.join(dirname, filename))\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import cv2\n","from tensorflow.keras.applications import VGG16, InceptionResNetV2\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["train_dir = \"../../../datasets/train/\" #passing the path with training images\n","test_dir = \"../../../datasets/test/\"   #passing the path with testing images"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["img_size = 48 #original size of the image"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["\"\"\"\n","Data Augmentation\n","--------------------------\n","rotation_range = rotates the image with the amount of degrees we provide\n","width_shift_range = shifts the image randomly to the right or left along the width of the image\n","height_shift range = shifts image randomly to up or below along the height of the image\n","horizontal_flip = flips the image horizontally\n","rescale = to scale down the pizel values in our image between 0 and 1\n","zoom_range = applies random zoom to our object\n","validation_split = reserves some images to be used for validation purpose\n","\"\"\"\n","\n","train_datagen = ImageDataGenerator(#rotation_range = 180,\n","                                         width_shift_range = 0.1,\n","                                         height_shift_range = 0.1,\n","                                         horizontal_flip = True,\n","                                         rescale = 1./255,\n","                                         #zoom_range = 0.2,\n","                                         validation_split = 0.2\n","                                        )\n","validation_datagen = ImageDataGenerator(rescale = 1./255,\n","                                         validation_split = 0.2)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 22968 images belonging to 7 classes.\n","Found 1432 images belonging to 7 classes.\n"]}],"source":["\"\"\"\n","Applying data augmentation to the images as we read \n","them from their respectivve directories\n","\"\"\"\n","train_generator = train_datagen.flow_from_directory(directory = train_dir,\n","                                                    target_size = (img_size,img_size),\n","                                                    batch_size = 64,\n","                                                    color_mode = \"grayscale\",\n","                                                    class_mode = \"categorical\",\n","                                                    subset = \"training\"\n","                                                   )\n","validation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n","                                                              target_size = (img_size,img_size),\n","                                                              batch_size = 64,\n","                                                              color_mode = \"grayscale\",\n","                                                              class_mode = \"categorical\",\n","                                                              subset = \"validation\"\n","                                                             )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\"\"\"\n","Modeling\n","\n","\n","model = Sequential()\n","model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu',input_shape=(img_size,img_size,1)))\n","model.add(MaxPool2D(pool_size = 2,strides = 2))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n","model.add(MaxPool2D(pool_size = 2,strides = 2))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n","model.add(MaxPool2D(pool_size = 2,strides = 2))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters = 256,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n","model.add(MaxPool2D(pool_size = 2,strides = 2))\n","model.add(BatchNormalization())\n","\n","model.add(Flatten())\n","model.add(Dense(units = 128,activation = 'relu',kernel_initializer='he_normal'))\n","model.add(Dropout(0.25))\n","model.add(Dense(units = 64,activation = 'relu',kernel_initializer='he_normal'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.25))\n","model.add(Dense(units = 32,activation = 'relu',kernel_initializer='he_normal'))\n","model.add(Dense(7,activation = 'softmax'))\n","\n","\"\"\""]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\davia\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}],"source":["model= tf.keras.models.Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\n","model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","    \n","model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten()) \n","model.add(Dense(256,activation = 'relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.25))\n","    \n","model.add(Dense(512,activation = 'relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(7, activation='softmax'))\n","\n","model.compile(\n","    optimizer = Adam(lr=0.0001), \n","    loss='categorical_crossentropy', \n","    metrics=['accuracy']\n","  )"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["epochs = 60\n","batch_size = 64"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 48, 48, 32)        320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n","                                                                 \n"," batch_normalization (BatchN  (None, 48, 48, 64)       256       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 24, 24, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 24, 24, 128)       204928    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 12, 12, 512)       590336    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 6, 6, 512)         2359808   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 4608)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               1179904   \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_4 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               131584    \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_5 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 7)                 3591      \n","                                                                 \n","=================================================================\n","Total params: 4,496,903\n","Trainable params: 4,492,935\n","Non-trainable params: 3,968\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/60\n","359/359 [==============================] - 637s 2s/step - loss: 9.2692 - accuracy: 0.1921 - val_loss: 8.9800 - val_accuracy: 0.1906\n","Epoch 2/60\n","359/359 [==============================] - 443s 1s/step - loss: 8.2143 - accuracy: 0.2329 - val_loss: 7.5917 - val_accuracy: 0.2458\n","Epoch 3/60\n","359/359 [==============================] - 440s 1s/step - loss: 7.2042 - accuracy: 0.2552 - val_loss: 6.5317 - val_accuracy: 0.2961\n","Epoch 4/60\n","359/359 [==============================] - 442s 1s/step - loss: 6.2193 - accuracy: 0.2798 - val_loss: 5.5911 - val_accuracy: 0.3317\n","Epoch 5/60\n","359/359 [==============================] - 441s 1s/step - loss: 5.3329 - accuracy: 0.3157 - val_loss: 4.7848 - val_accuracy: 0.3750\n","Epoch 6/60\n","359/359 [==============================] - 441s 1s/step - loss: 4.5662 - accuracy: 0.3511 - val_loss: 4.1461 - val_accuracy: 0.3966\n","Epoch 7/60\n","359/359 [==============================] - 447s 1s/step - loss: 3.9553 - accuracy: 0.3671 - val_loss: 3.5231 - val_accuracy: 0.4532\n","Epoch 8/60\n","359/359 [==============================] - 444s 1s/step - loss: 3.4451 - accuracy: 0.3944 - val_loss: 3.0876 - val_accuracy: 0.4553\n","Epoch 9/60\n","359/359 [==============================] - 446s 1s/step - loss: 3.0504 - accuracy: 0.4182 - val_loss: 2.9174 - val_accuracy: 0.4497\n","Epoch 10/60\n","359/359 [==============================] - 446s 1s/step - loss: 2.7219 - accuracy: 0.4386 - val_loss: 2.5465 - val_accuracy: 0.4860\n","Epoch 11/60\n","359/359 [==============================] - 444s 1s/step - loss: 2.4907 - accuracy: 0.4566 - val_loss: 2.4035 - val_accuracy: 0.4679\n","Epoch 12/60\n","359/359 [==============================] - 441s 1s/step - loss: 2.2860 - accuracy: 0.4772 - val_loss: 2.2702 - val_accuracy: 0.4658\n","Epoch 13/60\n","359/359 [==============================] - 443s 1s/step - loss: 2.1159 - accuracy: 0.4954 - val_loss: 1.9816 - val_accuracy: 0.5349\n","Epoch 14/60\n","359/359 [==============================] - 441s 1s/step - loss: 1.9838 - accuracy: 0.5103 - val_loss: 1.8241 - val_accuracy: 0.5608\n","Epoch 15/60\n","359/359 [==============================] - 441s 1s/step - loss: 1.8823 - accuracy: 0.5172 - val_loss: 1.6837 - val_accuracy: 0.5782\n","Epoch 16/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.7980 - accuracy: 0.5248 - val_loss: 1.6883 - val_accuracy: 0.5510\n","Epoch 17/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.7221 - accuracy: 0.5398 - val_loss: 1.5893 - val_accuracy: 0.5719\n","Epoch 18/60\n","359/359 [==============================] - 447s 1s/step - loss: 1.6692 - accuracy: 0.5453 - val_loss: 1.5405 - val_accuracy: 0.6027\n","Epoch 19/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.6218 - accuracy: 0.5536 - val_loss: 1.5067 - val_accuracy: 0.5908\n","Epoch 20/60\n","359/359 [==============================] - 496s 1s/step - loss: 1.5876 - accuracy: 0.5598 - val_loss: 1.5098 - val_accuracy: 0.5992\n","Epoch 21/60\n","359/359 [==============================] - 493s 1s/step - loss: 1.5563 - accuracy: 0.5649 - val_loss: 1.4317 - val_accuracy: 0.6166\n","Epoch 22/60\n","359/359 [==============================] - 491s 1s/step - loss: 1.5256 - accuracy: 0.5734 - val_loss: 1.4884 - val_accuracy: 0.5859\n","Epoch 23/60\n","359/359 [==============================] - 479s 1s/step - loss: 1.4969 - accuracy: 0.5849 - val_loss: 1.4228 - val_accuracy: 0.6138\n","Epoch 24/60\n","359/359 [==============================] - 491s 1s/step - loss: 1.4831 - accuracy: 0.5822 - val_loss: 1.4052 - val_accuracy: 0.6145\n","Epoch 25/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.4630 - accuracy: 0.5924 - val_loss: 1.3815 - val_accuracy: 0.6271\n","Epoch 26/60\n","359/359 [==============================] - 435s 1s/step - loss: 1.4540 - accuracy: 0.5949 - val_loss: 1.3903 - val_accuracy: 0.6103\n","Epoch 27/60\n","359/359 [==============================] - 437s 1s/step - loss: 1.4499 - accuracy: 0.5950 - val_loss: 1.4091 - val_accuracy: 0.6264\n","Epoch 28/60\n","359/359 [==============================] - 436s 1s/step - loss: 1.4280 - accuracy: 0.6038 - val_loss: 1.3707 - val_accuracy: 0.6418\n","Epoch 29/60\n","359/359 [==============================] - 483s 1s/step - loss: 1.4222 - accuracy: 0.6066 - val_loss: 1.3718 - val_accuracy: 0.6250\n","Epoch 30/60\n","359/359 [==============================] - 483s 1s/step - loss: 1.4183 - accuracy: 0.6105 - val_loss: 1.3821 - val_accuracy: 0.6334\n","Epoch 31/60\n","359/359 [==============================] - 484s 1s/step - loss: 1.4147 - accuracy: 0.6116 - val_loss: 1.3387 - val_accuracy: 0.6355\n","Epoch 32/60\n","359/359 [==============================] - 471s 1s/step - loss: 1.4009 - accuracy: 0.6179 - val_loss: 1.3678 - val_accuracy: 0.6306\n","Epoch 33/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3945 - accuracy: 0.6203 - val_loss: 1.3438 - val_accuracy: 0.6480\n","Epoch 34/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3904 - accuracy: 0.6237 - val_loss: 1.3546 - val_accuracy: 0.6522\n","Epoch 35/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3881 - accuracy: 0.6247 - val_loss: 1.3619 - val_accuracy: 0.6383\n","Epoch 36/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3889 - accuracy: 0.6265 - val_loss: 1.3839 - val_accuracy: 0.6327\n","Epoch 37/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3798 - accuracy: 0.6257 - val_loss: 1.3852 - val_accuracy: 0.6278\n","Epoch 38/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3741 - accuracy: 0.6324 - val_loss: 1.3442 - val_accuracy: 0.6480\n","Epoch 39/60\n","359/359 [==============================] - 473s 1s/step - loss: 1.3756 - accuracy: 0.6346 - val_loss: 1.3811 - val_accuracy: 0.6494\n","Epoch 40/60\n","359/359 [==============================] - 477s 1s/step - loss: 1.3622 - accuracy: 0.6440 - val_loss: 1.3658 - val_accuracy: 0.6425\n","Epoch 41/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3661 - accuracy: 0.6419 - val_loss: 1.3726 - val_accuracy: 0.6299\n","Epoch 42/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3574 - accuracy: 0.6448 - val_loss: 1.3698 - val_accuracy: 0.6459\n","Epoch 43/60\n","359/359 [==============================] - 445s 1s/step - loss: 1.3512 - accuracy: 0.6469 - val_loss: 1.3373 - val_accuracy: 0.6655\n","Epoch 44/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3557 - accuracy: 0.6460 - val_loss: 1.3611 - val_accuracy: 0.6627\n","Epoch 45/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3508 - accuracy: 0.6473 - val_loss: 1.3371 - val_accuracy: 0.6662\n","Epoch 46/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3449 - accuracy: 0.6493 - val_loss: 1.3822 - val_accuracy: 0.6515\n","Epoch 47/60\n","359/359 [==============================] - 444s 1s/step - loss: 1.3495 - accuracy: 0.6507 - val_loss: 1.4148 - val_accuracy: 0.6236\n","Epoch 48/60\n","359/359 [==============================] - 445s 1s/step - loss: 1.3409 - accuracy: 0.6562 - val_loss: 1.3298 - val_accuracy: 0.6585\n","Epoch 49/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3361 - accuracy: 0.6609 - val_loss: 1.3503 - val_accuracy: 0.6578\n","Epoch 50/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3379 - accuracy: 0.6595 - val_loss: 1.3580 - val_accuracy: 0.6599\n","Epoch 51/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3333 - accuracy: 0.6616 - val_loss: 1.3922 - val_accuracy: 0.6334\n","Epoch 52/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3309 - accuracy: 0.6601 - val_loss: 1.3383 - val_accuracy: 0.6697\n","Epoch 53/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3277 - accuracy: 0.6665 - val_loss: 1.3985 - val_accuracy: 0.6446\n","Epoch 54/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3289 - accuracy: 0.6618 - val_loss: 1.3845 - val_accuracy: 0.6585\n","Epoch 55/60\n","359/359 [==============================] - 445s 1s/step - loss: 1.3295 - accuracy: 0.6661 - val_loss: 1.3498 - val_accuracy: 0.6634\n","Epoch 56/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3150 - accuracy: 0.6697 - val_loss: 1.4135 - val_accuracy: 0.6480\n","Epoch 57/60\n","359/359 [==============================] - 442s 1s/step - loss: 1.3226 - accuracy: 0.6687 - val_loss: 1.3558 - val_accuracy: 0.6676\n","Epoch 58/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3247 - accuracy: 0.6698 - val_loss: 1.3884 - val_accuracy: 0.6571\n","Epoch 59/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3162 - accuracy: 0.6731 - val_loss: 1.3607 - val_accuracy: 0.6613\n","Epoch 60/60\n","359/359 [==============================] - 443s 1s/step - loss: 1.3167 - accuracy: 0.6726 - val_loss: 1.3973 - val_accuracy: 0.6487\n"]}],"source":["history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig , ax = plt.subplots(1,2)\n","train_acc = history.history['accuracy']\n","train_loss = history.history['loss']\n","fig.set_size_inches(12,4)\n","\n","ax[0].plot(history.history['accuracy'])\n","ax[0].plot(history.history['val_accuracy'])\n","ax[0].set_title('Training Accuracy vs Validation Accuracy')\n","ax[0].set_ylabel('Accuracy')\n","ax[0].set_xlabel('Epoch')\n","ax[0].legend(['Train', 'Validation'], loc='upper left')\n","\n","ax[1].plot(history.history['loss'])\n","ax[1].plot(history.history['val_loss'])\n","ax[1].set_title('Training Loss vs Validation Loss')\n","ax[1].set_ylabel('Loss')\n","ax[1].set_xlabel('Epoch')\n","ax[1].legend(['Train', 'Validation'], loc='upper left')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["model.save('model_optimal.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img = image.load_img(\"../input/emotion-detection-fer/test/happy/im1021.png\",target_size = (48,48),color_mode = \"grayscale\")\n","img = np.array(img)\n","plt.imshow(img)\n","print(img.shape) #prints (48,48) that is the shape of our image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img = np.expand_dims(img,axis = 0) #makes image shape (1,48,48)\n","img = img.reshape(1,48,48,1)\n","result = model.predict(img)\n","result = list(result[0])\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["img_index = result.index(max(result))\n","print(label_dict[img_index])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_loss, train_acc = model.evaluate(train_generator)\n","test_loss, test_acc   = model.evaluate(validation_generator)\n","print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_acc*100, test_acc*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save_weights('model_weights.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"vscode":{"interpreter":{"hash":"68a5dccc06dabba8123a9719d3c0aefc6a0fa5ae97ebf65da59da10678a0f5ec"}}},"nbformat":4,"nbformat_minor":4}
